
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>Running Experiments with WholeBrain_MVPA</title><meta name="generator" content="MATLAB 9.0"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2017-08-12"><meta name="DC.source" content="demo00.m"><style type="text/css">
html,body,div,span,applet,object,iframe,h1,h2,h3,h4,h5,h6,p,blockquote,pre,a,abbr,acronym,address,big,cite,code,del,dfn,em,font,img,ins,kbd,q,s,samp,small,strike,strong,sub,sup,tt,var,b,u,i,center,dl,dt,dd,ol,ul,li,fieldset,form,label,legend,table,caption,tbody,tfoot,thead,tr,th,td{margin:0;padding:0;border:0;outline:0;font-size:100%;vertical-align:baseline;background:transparent}body{line-height:1}ol,ul{list-style:none}blockquote,q{quotes:none}blockquote:before,blockquote:after,q:before,q:after{content:'';content:none}:focus{outine:0}ins{text-decoration:none}del{text-decoration:line-through}table{border-collapse:collapse;border-spacing:0}

html { min-height:100%; margin-bottom:1px; }
html body { height:100%; margin:0px; font-family:Arial, Helvetica, sans-serif; font-size:10px; color:#000; line-height:140%; background:#fff none; overflow-y:scroll; }
html body td { vertical-align:top; text-align:left; }

h1 { padding:0px; margin:0px 0px 25px; font-family:Arial, Helvetica, sans-serif; font-size:1.5em; color:#d55000; line-height:100%; font-weight:normal; }
h2 { padding:0px; margin:0px 0px 8px; font-family:Arial, Helvetica, sans-serif; font-size:1.2em; color:#000; font-weight:bold; line-height:140%; border-bottom:1px solid #d6d4d4; display:block; }
h3 { padding:0px; margin:0px 0px 5px; font-family:Arial, Helvetica, sans-serif; font-size:1.1em; color:#000; font-weight:bold; line-height:140%; }

a { color:#005fce; text-decoration:none; }
a:hover { color:#005fce; text-decoration:underline; }
a:visited { color:#004aa0; text-decoration:none; }

p { padding:0px; margin:0px 0px 20px; }
img { padding:0px; margin:0px 0px 20px; border:none; }
p img, pre img, tt img, li img, h1 img, h2 img { margin-bottom:0px; } 

ul { padding:0px; margin:0px 0px 20px 23px; list-style:square; }
ul li { padding:0px; margin:0px 0px 7px 0px; }
ul li ul { padding:5px 0px 0px; margin:0px 0px 7px 23px; }
ul li ol li { list-style:decimal; }
ol { padding:0px; margin:0px 0px 20px 0px; list-style:decimal; }
ol li { padding:0px; margin:0px 0px 7px 23px; list-style-type:decimal; }
ol li ol { padding:5px 0px 0px; margin:0px 0px 7px 0px; }
ol li ol li { list-style-type:lower-alpha; }
ol li ul { padding-top:7px; }
ol li ul li { list-style:square; }

.content { font-size:1.2em; line-height:140%; padding: 20px; }

pre, code { font-size:12px; }
tt { font-size: 1.2em; }
pre { margin:0px 0px 20px; }
pre.codeinput { padding:10px; border:1px solid #d3d3d3; background:#f7f7f7; }
pre.codeoutput { padding:10px 11px; margin:0px 0px 20px; color:#4c4c4c; }
pre.error { color:red; }

@media print { pre.codeinput, pre.codeoutput { word-wrap:break-word; width:100%; } }

span.keyword { color:#0000FF }
span.comment { color:#228B22 }
span.string { color:#A020F0 }
span.untermstring { color:#B20000 }
span.syscmd { color:#B28C00 }

.footer { width:auto; padding:10px 0px; margin:25px 0px 0px; border-top:1px dotted #878787; font-size:0.8em; line-height:140%; font-style:italic; color:#878787; text-align:left; float:none; }
.footer p { margin:0px; }
.footer a { color:#878787; }
.footer a:hover { color:#878787; text-decoration:underline; }
.footer a:visited { color:#878787; }

table th { padding:7px 5px; text-align:left; vertical-align:middle; border: 1px solid #d6d4d4; font-weight:bold; }
table td { padding:7px 5px; text-align:left; vertical-align:top; border:1px solid #d6d4d4; }





  </style></head><body><div class="content"><h1>Running Experiments with WholeBrain_MVPA</h1><!--introduction--><!--/introduction--><h2>Contents</h2><div><ul><li><a href="#1">The data</a></li><li><a href="#2">metadata.targets</a></li><li><a href="#3">Put it all together</a></li><li><a href="#4">Save the data to disk</a></li><li><a href="#5">Define a parameter file</a></li><li><a href="#6">Run WholeBrain_MVPA: SOS Lasso</a></li><li><a href="#7">Run WholeBrain_MVPA: Searchlight</a></li></ul></div><h2>The data<a name="1"></a></h2><p>The fMRI data should be formatted so that each row is a training <i>example</i>, and the columns are the <i>features</i> that express each example. An <i>example</i> might correspond to the activation over voxels at a particular point in time, the beta values or t-values resulting from an initial univariate model of a design matrix convolved with an HRF, or anything else you like. Each feature, for our purposes, is a voxel.</p><div><ul><li>This matrix can be named whatever you like.</li><li>It must be saved in a .mat file, either on it's own or along with other   variables.</li><li>The .mat file itself can be named whatever you like, with the one   constraint that WholeBrain_MVPA will expect a subject number to be   present somewhere in the filename.</li><li>Numbers can be zero padded.</li></ul></div><p>In this demo, we'll call the matrix <tt>X</tt>, which will be the only variable we save to the .mat file.</p><p>Imagine a study with 100 unique items, sampled equally from two categories or belonging to two experimental conditions. Further, imagine that there are 10,000 voxels in the cortex of this subject.</p><p>Let <tt>y</tt> represent the category or condition labels of the items. This is the target structure that we will be modelling based on the data in <tt>X</tt>. Since all methods in this package are binary classifiers, <tt>y</tt> should be binary. We'll make <tt>y</tt> dependent on independent contributions from 10 voxels.</p><pre class="codeinput">nitems = 100;
nvoxels = 1000;
X = randn(nitems, nvoxels);

b = zeros(nvoxels, 1);
b(1:10) = 10;
y = X*b;
y = y &gt; median(y);

tabulate(y);
</pre><pre class="codeoutput">  Value    Count   Percent
      0       50     50.00%
      1       50     50.00%
</pre><h2>metadata.targets<a name="2"></a></h2><p>Information about targets (i.e., possible y vectors) should be stored in a structure with 5 required fields:</p><div><ol><li><tt>label</tt></li><li><tt>type</tt></li><li><tt>targets</tt></li><li><tt>sim_source</tt></li><li><tt>sim_metric</tt></li></ol></div><p>Only the first three are relevant for classification analyses, but all must be present.</p><pre class="codeinput">TARGETS(1) = struct(<span class="keyword">...</span>
  <span class="string">'label'</span>,<span class="string">'faces'</span>,<span class="keyword">...</span>
  <span class="string">'type'</span>,<span class="string">'category'</span>,<span class="keyword">...</span>
  <span class="string">'target'</span>,y, <span class="keyword">...</span>
  <span class="string">'sim_source'</span>,[],<span class="string">'sim_metric'</span>,[]);
TARGETS(2) = struct(<span class="keyword">...</span>
  <span class="string">'label'</span>,<span class="string">'places'</span>,<span class="keyword">...</span>
  <span class="string">'type'</span>,<span class="string">'category'</span>,<span class="keyword">...</span>
  <span class="string">'target'</span>,~y, <span class="keyword">...</span>
  <span class="string">'sim_source'</span>,[],<span class="string">'sim_metric'</span>,[]);

<span class="comment">% Cross-validation</span>
<span class="comment">% ----------------</span>
<span class="comment">% The methods in WholeBrain_MVPA will not generate CV indexes for you. This is</span>
<span class="comment">% to help promote replicability of results. So you will need to provide a cross</span>
<span class="comment">% validation scheme ahead of time. If you are concerned about results being</span>
<span class="comment">% specific to a particular cross-validation scheme, you can specify multiple</span>
<span class="comment">% schemes.</span>
<span class="comment">%</span>
<span class="comment">% For example, let's set up 10 cross validation schemes.</span>
nschemes = 10;
nfolds = 10;
SCHEMES = zeros(nitems, nschemes);
<span class="keyword">for</span> iScheme = 1:nschemes
  c = cvpartition(y,<span class="string">'KFold'</span>, nfolds);
  <span class="keyword">for</span> iFold = 1:nfolds
    SCHEMES(:,iScheme) = SCHEMES(:,iScheme) + (test(c, iFold) * iFold);
  <span class="keyword">end</span>
<span class="keyword">end</span>

<span class="comment">% Filters</span>
<span class="comment">% -------</span>
<span class="comment">% You may want to be able to select/exclude subsets of voxels and items without</span>
<span class="comment">% needed to make multiple copies of the data. By specifying filters, you can</span>
<span class="comment">% pre-specify these subsets and apply them programmatically.</span>
<span class="comment">% A filter is represented as a structure with 3 required fields: label,</span>
<span class="comment">% dimension, and filter. The label names the filter so that it can be easily</span>
<span class="comment">% referenced later, dimension encodes whether the filter applies to rows (1) or</span>
<span class="comment">% columns (2) of X. The filter is a binary vectory that represents the filter</span>
<span class="comment">% itself.</span>
<span class="comment">% Here, lets set up (totally arbitrarily) a ROI filter and a filter to exclude</span>
<span class="comment">% outliers.</span>
z = [true(500,1);false(9500,1)];
FILTERS(1) = struct(<span class="string">'label'</span>,<span class="string">'ROI01'</span>, <span class="string">'dimension'</span>, 2, <span class="string">'filter'</span>, z);
z = [true(98,1);false(2,1)];
FILTERS(2) = struct(<span class="string">'label'</span>,<span class="string">'GoodRows'</span>, <span class="string">'dimension'</span>, 1, <span class="string">'filter'</span>, z);

<span class="comment">% Coordinates</span>
<span class="comment">% -----------</span>
<span class="comment">% It is useful (and in the case of SOS Lasso, essential) that the voxel</span>
<span class="comment">% coordinates be represented in the metadata structure. Like filters,</span>
<span class="comment">% coordinates are represented in a structure. The coordinate structure has 2</span>
<span class="comment">% required fields: 'orientation' and 'xyz'. The 'orientation' field is like the</span>
<span class="comment">% 'label' field in the filter structure and is used to look up particular</span>
<span class="comment">% coordinates. Labeling different coordinate spaces by 'orientation' is an AFNI</span>
<span class="comment">% convention. You don't have to use orientation codes like 'tlrc', 'orig', and</span>
<span class="comment">% 'mni', but that is my convention.</span>
xyz = [(1:nvoxels)',ones(nvoxels,1),ones(nvoxels,1)];
COORDS(1) = struct(<span class="string">'orientation'</span>,<span class="string">'orig'</span>,<span class="string">'xyz'</span>,xyz);
COORDS(2) = struct(<span class="string">'orientation'</span>,<span class="string">'tlrc'</span>,<span class="string">'xyz'</span>,xyz);
<span class="comment">% Of course, in practice the tlrc coordinates would not be the same as the</span>
<span class="comment">% original coordinates ...</span>
</pre><h2>Put it all together<a name="3"></a></h2><p>------------------- The metadata object compiles these three items, along with a couple other bits, into a single structure. The metadata structure has several required fields: 'subject', 'targets', 'filters', 'coords', 'cvind', 'nrow', 'ncol'. There will be a metadata structure for each subject, compiled into a structured array. Although in the example below subjects 100 and 101 are the same aside from their subject numbers, in practice they could be given different information.</p><pre class="codeinput">metadata(1).subject = 100;
metadata(1).targets = TARGETS;
metadata(1).filters = FILTERS;
metadata(1).coords = COORDS;
metadata(1).cvind = SCHEMES;
metadata(1).nrow = nitems;
metadata(1).ncol = nvoxels;
metadata(2).subject = 101;
metadata(2).targets = TARGETS;
metadata(2).filters = FILTERS;
metadata(2).coords = COORDS;
metadata(2).cvind = SCHEMES;
metadata(2).nrow = nitems;
metadata(2).ncol = nvoxels;
</pre><h2>Save the data to disk<a name="4"></a></h2><pre>=====================
Despite having data and metadata organized properly in memory, before working
with WholeBrain_MVPA we need to write the data to disk. The reason for this
is that WholeBrain_MVPA is not written to be used interactively, but rather
to facilitate to use in headless, batch applications particularly on
distributed computing systems. WholeBrain_MVPA accepts paths to files on
disk, as well as many other parameters.
The data and metadata should be saved to a central location where it can be
easily referenced.
These files can be named whatever you like. You will be referencing them with
explicit paths, and WholeBrain_MVPA does not make any assumptions about them.
The program does assume that the *variable* names are X and metadata, but
this default can be overwritten with certain parameters to WholeBrain_MVPA
(data_var and metadata_var) if you prefer another convention.</pre><pre class="codeinput">subjects = [metadata.subject];
datadir = <span class="string">'./shared'</span>;
<span class="keyword">if</span> ~exist(datadir,<span class="string">'dir'</span>)
    mkdir(datadir);
<span class="keyword">end</span>
<span class="keyword">for</span> iSubj = 1:2
  s = subjects(iSubj);
  X = randn(nitems, nvoxels);
  X(1:50,1:20) = X(1:50,1:20) + 2;
  filename = sprintf(<span class="string">'s%03d.mat'</span>, s);
  filepath = fullfile(datadir,filename);
  save(filepath, <span class="string">'X'</span>);
<span class="keyword">end</span>
save(fullfile(datadir,<span class="string">'metadata.mat'</span>), <span class="string">'metadata'</span>);
</pre><h2>Define a parameter file<a name="5"></a></h2><pre>=======================
WholeBrain_MVPA, despite being written as a Matlab function, is a very ugly
function. First of all, it does not return anything. All results are written
to disk. Likewise, although it is possible to invoke WholeBrain_MVPA from
within a script or at the interactive terminal, it is designed to look for a
parameter file if no arguments are provided. This is all makes
WholeBrain_MVPA a bit counter-intuitive. However, these design choices make
much more sense when considered in a distributed computing environment.
WholeBrain_MVPA can be deployed to a system, along with a json file
containing parameters, and it will parse the file and execute according to
the instructions. It is designed to be executed with bare minimum interaction.</pre><p>Defining a parameter file is simple. See the documentation for a list of valid parameters. WholeBrain_MVPA reads json (<a href="http://www.json.org/">http://www.json.org/</a>), which is a widely used text-based syntax for representing structured data.</p><pre>         **The file must be named params.json**</pre><p>To read and write json, you will need jsonlab (<a href="http://www.mathworks.com/matlabcentral/fileexchange/33381-jsonlab--a-toolbox-to-encode-decode-json-files">http://www.mathworks.com/matlabcentral/fileexchange/33381-jsonlab--a-toolbox-to-encode-decode-json-files</a>) which I have bundled with my code:</p><pre class="codeinput">addpath(<span class="string">'../dependencies/jsonlab/'</span>);

<span class="comment">% Put the parameter file where you want to run the analysis. Paths can be</span>
<span class="comment">% relative with respect to where you execute WholeBrain_MVPA, but in most cases</span>
<span class="comment">% it will probably make sense for them to be absolute. The following should</span>
<span class="comment">% translate into a valid json file for the purpose of this demo.</span>
params = struct(<span class="string">'regularization'</span>, <span class="string">'soslasso'</span>, <span class="string">'bias'</span>, false, <span class="string">'alpha'</span>, 0.4200556,<span class="keyword">...</span>
    <span class="string">'lambda'</span>, 0.5863, <span class="string">'shape'</span>, <span class="string">'sphere'</span>, <span class="string">'diameter'</span>, 18, <span class="string">'overlap'</span>, 9,<span class="keyword">...</span>
    <span class="string">'cvscheme'</span>, 1,<span class="string">'cvholdout'</span>, 1:10, <span class="string">'finalholdout'</span>, 0, <span class="string">'target'</span>, <span class="string">'faces'</span>,<span class="keyword">...</span>
    <span class="string">'data'</span>, {{<span class="string">'./shared/s100.mat'</span>, <span class="string">'./shared/s101.mat'</span>}}, <span class="string">'data_var'</span>, <span class="string">'X'</span>,<span class="keyword">...</span>
    <span class="string">'normalize'</span>, <span class="string">'zscore'</span>, <span class="string">'metadata'</span>, <span class="string">'./shared/metadata.mat'</span>,<span class="keyword">...</span>
    <span class="string">'metadata_var'</span>, <span class="string">'metadata'</span>, <span class="string">'orientation'</span>, <span class="string">'tlrc'</span>, <span class="string">'filters'</span>, <span class="keyword">...</span>
    {{<span class="string">'ROI01'</span>,<span class="string">'GoodRows'</span>}}, <span class="string">'SmallFootprint'</span>, false, <span class="string">'debug'</span>, false,<span class="keyword">...</span>
    <span class="string">'SaveResultsAs'</span>,<span class="string">'json'</span>,<span class="string">'subject_id_fmt'</span>,<span class="string">'s%d.mat'</span>);
savejson(<span class="string">''</span>,params,<span class="string">'FileName'</span>,<span class="string">'params.json'</span>,<span class="string">'ForceRootName'</span>,false);
</pre><pre class="codeoutput">Warning: Name is nonexistent or not a directory: ..\dependencies\jsonlab 
</pre><pre class="codeoutput error">Undefined function 'savejson' for input arguments of type 'struct'.

Error in demo00 (line 207)
savejson('',params,'FileName','params.json','ForceRootName',false);
</pre><h2>Run WholeBrain_MVPA: SOS Lasso<a name="6"></a></h2><pre>==============================
With data and metadata structured properly and saved to disk, and with a
parameter file named params.json in a folder where you would like to execute
the analysis and return results, all that remains is to boot up Matlab in the
directory that contains 'params.json' and execute WholeBrain_MVPA() at the
command prompt. If you have compiled WholeBrain_MVPA into an executable (as
would be necessary on a distributed computing cluster), you can execute
Wholebrain_MVPA directly from the command line. In either case, it will read
the parameter file and begin analysis. When it completes you will find a
results.mat (or results.json) file in the directory where WholeBrain_MVPA was
executed.</pre><pre class="codeinput">addpath(<span class="string">'../src/'</span>)
WholeBrain_MVPA()
</pre><h2>Run WholeBrain_MVPA: Searchlight<a name="7"></a></h2><pre>================================
Put the parameter file where you want to run the analysis. Paths can be
relative with respect to where you execute WholeBrain_MVPA, but in most cases
it will probably make sense for them to be absolute. The following should
translate into a valid json file for the purpose of this demo.</pre><pre class="codeinput">params = struct(<span class="string">'algorithm'</span>, <span class="string">'soslasso'</span>, <span class="string">'bias'</span>, false, <span class="string">'alpha'</span>, 0.4200556,<span class="keyword">...</span>
    <span class="string">'lambda'</span>, 0.5863, <span class="string">'shape'</span>, <span class="string">'sphere'</span>, <span class="string">'diameter'</span>, 18, <span class="string">'overlap'</span>, 9,<span class="keyword">...</span>
    <span class="string">'cvscheme'</span>, 1,<span class="string">'cvholdout'</span>, 1:10, <span class="string">'finalholdout'</span>, 0, <span class="string">'target'</span>, <span class="string">'faces'</span>,<span class="keyword">...</span>
    <span class="string">'data'</span>, {{<span class="string">'./shared/s100.mat'</span>, <span class="string">'./shared/s101.mat'</span>}}, <span class="string">'data_var'</span>, <span class="string">'X'</span>,<span class="keyword">...</span>
    <span class="string">'normalize'</span>, <span class="string">'zscore'</span>, <span class="string">'metadata'</span>, <span class="string">'./shared/metadata.mat'</span>,<span class="keyword">...</span>
    <span class="string">'metadata_var'</span>, <span class="string">'metadata'</span>, <span class="string">'orientation'</span>, <span class="string">'tlrc'</span>, <span class="string">'filters'</span>, <span class="keyword">...</span>
    {{<span class="string">'ROI01'</span>,<span class="string">'GoodRows'</span>}}, <span class="string">'SmallFootprint'</span>, false, <span class="string">'debug'</span>, false,<span class="keyword">...</span>
    <span class="string">'SaveResultsAs'</span>,<span class="string">'json'</span>,<span class="string">'subject_id_fmt'</span>,<span class="string">'s%d.mat'</span>);
savejson(<span class="string">''</span>,params,<span class="string">'FileName'</span>,<span class="string">'params.json'</span>,<span class="string">'ForceRootName'</span>,false);

<span class="comment">% Compile Results</span>
<span class="comment">% ===============</span>
<span class="comment">% If you are using WholeBrain_MVPA on a distributed computing cluster, you will</span>
<span class="comment">% quickly find that the volume of results is difficult to manage effectively. I</span>
<span class="comment">% have written some utility functions in Wholebrain_MVPA/util that attempt to</span>
<span class="comment">% facilitate common actions, like loading data from many jobs into a single</span>
<span class="comment">% matlab structure, writing tables of data, dumping coordinates of identified</span>
<span class="comment">% voxels, etc.</span>
<span class="comment">% Alternatively, you may find that your volume of data demands a database</span>
<span class="comment">% solution. Although the default is to return data in .mat files, which makes</span>
<span class="comment">% it easy to read back into matlab, results can also be output in json format</span>
<span class="comment">% which facilitates storing in a SQL or NoSQL database like MongoDB. Setting up</span>
<span class="comment">% such a database solution is far beyond the scope of this demo, but the squall</span>
<span class="comment">% project (github.com/ikinsella/squall) is a developing solution that utilizes</span>
<span class="comment">% MongoDB to great effect.</span>
</pre><p class="footer"><br><a href="http://www.mathworks.com/products/matlab/">Published with MATLAB&reg; R2016a</a><br></p></div><!--
##### SOURCE BEGIN #####
%% Running Experiments with WholeBrain_MVPA
%% The data
% The fMRI data should be formatted so that each row is a training
% _example_, and the columns are the _features_ that express each example.
% An _example_ might correspond to the activation over voxels at a
% particular point in time, the beta values or t-values resulting from an
% initial univariate model of a design matrix convolved with an HRF, or
% anything else you like. Each feature, for our purposes, is a voxel. 
%
% * This matrix can be named whatever you like.
% * It must be saved in a .mat file, either on it's own or along with other
%   variables.
% * The .mat file itself can be named whatever you like, with the one
%   constraint that WholeBrain_MVPA will expect a subject number to be
%   present somewhere in the filename.
% * Numbers can be zero padded.
%
% In this demo, we'll call the matrix |X|, which will be the only variable we save to the .mat file.
%
% Imagine a study with 100 unique items, sampled equally from two
% categories or belonging to two experimental conditions. Further, imagine that
% there are 10,000 voxels in the cortex of this subject.
%
% Let |y| represent the category or condition labels of the items. This is
% the target structure that we will be modelling based on the data in |X|.
% Since all methods in this package are binary classifiers, |y| should be
% binary. We'll make |y| dependent on independent contributions from 10
% voxels.

nitems = 100;
nvoxels = 1000;
X = randn(nitems, nvoxels);

b = zeros(nvoxels, 1);
b(1:10) = 10;
y = X*b;
y = y > median(y);

tabulate(y);

%% metadata.targets
% Information about targets (i.e., possible y vectors) should be stored in a
% structure with 5 required fields:
% 
% # |label|
% # |type|
% # |targets|
% # |sim_source|
% # |sim_metric|
%
% Only the first three are relevant for classification analyses, but all
% must be present.

TARGETS(1) = struct(...
  'label','faces',...
  'type','category',...
  'target',y, ...
  'sim_source',[],'sim_metric',[]);
TARGETS(2) = struct(...
  'label','places',...
  'type','category',...
  'target',~y, ...
  'sim_source',[],'sim_metric',[]);

% Cross-validation
% REPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASH
% The methods in WholeBrain_MVPA will not generate CV indexes for you. This is
% to help promote replicability of results. So you will need to provide a cross
% validation scheme ahead of time. If you are concerned about results being
% specific to a particular cross-validation scheme, you can specify multiple
% schemes.
%
% For example, let's set up 10 cross validation schemes.
nschemes = 10;
nfolds = 10;
SCHEMES = zeros(nitems, nschemes);
for iScheme = 1:nschemes
  c = cvpartition(y,'KFold', nfolds);
  for iFold = 1:nfolds
    SCHEMES(:,iScheme) = SCHEMES(:,iScheme) + (test(c, iFold) * iFold);
  end
end

% Filters
% REPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASH-
% You may want to be able to select/exclude subsets of voxels and items without
% needed to make multiple copies of the data. By specifying filters, you can
% pre-specify these subsets and apply them programmatically.
% A filter is represented as a structure with 3 required fields: label,
% dimension, and filter. The label names the filter so that it can be easily
% referenced later, dimension encodes whether the filter applies to rows (1) or
% columns (2) of X. The filter is a binary vectory that represents the filter
% itself.
% Here, lets set up (totally arbitrarily) a ROI filter and a filter to exclude
% outliers.
z = [true(500,1);false(9500,1)];
FILTERS(1) = struct('label','ROI01', 'dimension', 2, 'filter', z);
z = [true(98,1);false(2,1)];
FILTERS(2) = struct('label','GoodRows', 'dimension', 1, 'filter', z);

% Coordinates
% REPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASH-
% It is useful (and in the case of SOS Lasso, essential) that the voxel
% coordinates be represented in the metadata structure. Like filters,
% coordinates are represented in a structure. The coordinate structure has 2
% required fields: 'orientation' and 'xyz'. The 'orientation' field is like the
% 'label' field in the filter structure and is used to look up particular
% coordinates. Labeling different coordinate spaces by 'orientation' is an AFNI
% convention. You don't have to use orientation codes like 'tlrc', 'orig', and
% 'mni', but that is my convention.
xyz = [(1:nvoxels)',ones(nvoxels,1),ones(nvoxels,1)];
COORDS(1) = struct('orientation','orig','xyz',xyz);
COORDS(2) = struct('orientation','tlrc','xyz',xyz);
% Of course, in practice the tlrc coordinates would not be the same as the
% original coordinates ...

%% Put it all together
% REPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASH-
% The metadata object compiles these three items, along with a couple other
% bits, into a single structure. The metadata structure has several required
% fields: 'subject', 'targets', 'filters', 'coords', 'cvind', 'nrow', 'ncol'.
% There will be a metadata structure for each subject, compiled into a
% structured array. Although in the example below subjects 100 and 101 are the
% same aside from their subject numbers, in practice they could be given
% different information.
metadata(1).subject = 100;
metadata(1).targets = TARGETS;
metadata(1).filters = FILTERS;
metadata(1).coords = COORDS;
metadata(1).cvind = SCHEMES;
metadata(1).nrow = nitems;
metadata(1).ncol = nvoxels;
metadata(2).subject = 101;
metadata(2).targets = TARGETS;
metadata(2).filters = FILTERS;
metadata(2).coords = COORDS;
metadata(2).cvind = SCHEMES;
metadata(2).nrow = nitems;
metadata(2).ncol = nvoxels;

%% Save the data to disk
%  =====================
% Despite having data and metadata organized properly in memory, before working
% with WholeBrain_MVPA we need to write the data to disk. The reason for this
% is that WholeBrain_MVPA is not written to be used interactively, but rather
% to facilitate to use in headless, batch applications particularly on
% distributed computing systems. WholeBrain_MVPA accepts paths to files on
% disk, as well as many other parameters.
% The data and metadata should be saved to a central location where it can be
% easily referenced.
% These files can be named whatever you like. You will be referencing them with
% explicit paths, and WholeBrain_MVPA does not make any assumptions about them.
% The program does assume that the *variable* names are X and metadata, but
% this default can be overwritten with certain parameters to WholeBrain_MVPA
% (data_var and metadata_var) if you prefer another convention.
subjects = [metadata.subject];
datadir = './shared';
if ~exist(datadir,'dir')
    mkdir(datadir);
end
for iSubj = 1:2
  s = subjects(iSubj);
  X = randn(nitems, nvoxels);
  X(1:50,1:20) = X(1:50,1:20) + 2;
  filename = sprintf('s%03d.mat', s);
  filepath = fullfile(datadir,filename);
  save(filepath, 'X');
end
save(fullfile(datadir,'metadata.mat'), 'metadata');

%% Define a parameter file
%  =======================
% WholeBrain_MVPA, despite being written as a Matlab function, is a very ugly
% function. First of all, it does not return anything. All results are written
% to disk. Likewise, although it is possible to invoke WholeBrain_MVPA from
% within a script or at the interactive terminal, it is designed to look for a
% parameter file if no arguments are provided. This is all makes
% WholeBrain_MVPA a bit counter-intuitive. However, these design choices make
% much more sense when considered in a distributed computing environment.
% WholeBrain_MVPA can be deployed to a system, along with a json file
% containing parameters, and it will parse the file and execute according to
% the instructions. It is designed to be executed with bare minimum interaction.
%
% Defining a parameter file is simple. See the documentation for a list of
% valid parameters. WholeBrain_MVPA reads json (http://www.json.org/), which is
% a widely used text-based syntax for representing structured data.
%
%           **The file must be named params.json**
%
% To read and write json, you will need jsonlab
% (http://www.mathworks.com/matlabcentral/fileexchange/33381-jsonlabREPLACE_WITH_DASH_DASHa-toolbox-to-encode-decode-json-files)
% which I have bundled with my code:
addpath('../dependencies/jsonlab/');

% Put the parameter file where you want to run the analysis. Paths can be
% relative with respect to where you execute WholeBrain_MVPA, but in most cases
% it will probably make sense for them to be absolute. The following should
% translate into a valid json file for the purpose of this demo. 
params = struct('regularization', 'soslasso', 'bias', false, 'alpha', 0.4200556,...
    'lambda', 0.5863, 'shape', 'sphere', 'diameter', 18, 'overlap', 9,...
    'cvscheme', 1,'cvholdout', 1:10, 'finalholdout', 0, 'target', 'faces',...
    'data', {{'./shared/s100.mat', './shared/s101.mat'}}, 'data_var', 'X',...
    'normalize', 'zscore', 'metadata', './shared/metadata.mat',...
    'metadata_var', 'metadata', 'orientation', 'tlrc', 'filters', ...
    {{'ROI01','GoodRows'}}, 'SmallFootprint', false, 'debug', false,...
    'SaveResultsAs','json','subject_id_fmt','s%d.mat');
savejson('',params,'FileName','params.json','ForceRootName',false);

%% Run WholeBrain_MVPA: SOS Lasso
%  ==============================
% With data and metadata structured properly and saved to disk, and with a
% parameter file named params.json in a folder where you would like to execute
% the analysis and return results, all that remains is to boot up Matlab in the
% directory that contains 'params.json' and execute WholeBrain_MVPA() at the
% command prompt. If you have compiled WholeBrain_MVPA into an executable (as
% would be necessary on a distributed computing cluster), you can execute
% Wholebrain_MVPA directly from the command line. In either case, it will read
% the parameter file and begin analysis. When it completes you will find a
% results.mat (or results.json) file in the directory where WholeBrain_MVPA was
% executed.
addpath('../src/')
WholeBrain_MVPA()

%%  Run WholeBrain_MVPA: Searchlight
%  ================================
% Put the parameter file where you want to run the analysis. Paths can be
% relative with respect to where you execute WholeBrain_MVPA, but in most cases
% it will probably make sense for them to be absolute. The following should
% translate into a valid json file for the purpose of this demo. 
params = struct('algorithm', 'soslasso', 'bias', false, 'alpha', 0.4200556,...
    'lambda', 0.5863, 'shape', 'sphere', 'diameter', 18, 'overlap', 9,...
    'cvscheme', 1,'cvholdout', 1:10, 'finalholdout', 0, 'target', 'faces',...
    'data', {{'./shared/s100.mat', './shared/s101.mat'}}, 'data_var', 'X',...
    'normalize', 'zscore', 'metadata', './shared/metadata.mat',...
    'metadata_var', 'metadata', 'orientation', 'tlrc', 'filters', ...
    {{'ROI01','GoodRows'}}, 'SmallFootprint', false, 'debug', false,...
    'SaveResultsAs','json','subject_id_fmt','s%d.mat');
savejson('',params,'FileName','params.json','ForceRootName',false);

% Compile Results
% ===============
% If you are using WholeBrain_MVPA on a distributed computing cluster, you will
% quickly find that the volume of results is difficult to manage effectively. I
% have written some utility functions in Wholebrain_MVPA/util that attempt to
% facilitate common actions, like loading data from many jobs into a single
% matlab structure, writing tables of data, dumping coordinates of identified
% voxels, etc.
% Alternatively, you may find that your volume of data demands a database
% solution. Although the default is to return data in .mat files, which makes
% it easy to read back into matlab, results can also be output in json format
% which facilitates storing in a SQL or NoSQL database like MongoDB. Setting up
% such a database solution is far beyond the scope of this demo, but the squall
% project (github.com/ikinsella/squall) is a developing solution that utilizes
% MongoDB to great effect.

##### SOURCE END #####
--></body></html>